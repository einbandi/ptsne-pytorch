{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import root_scalar, curve_fit\n",
    "from pynndescent import NNDescent\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/\\\n",
    "0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_k(dists, sigma):\n",
    "    return np.exp(- (dists - dists[0]) / sigma).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sigma(d, k, lower_bound=1e-6, upper_bound=1e6):\n",
    "    return root_scalar(\n",
    "        lambda s: exp_k(d, s) - np.log2(k),\n",
    "        bracket=(lower_bound, upper_bound)\n",
    "    ).root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_ij_sym(x, k, verbose=False):\n",
    "    num_pts = x.shape[0]\n",
    "    if verbose:\n",
    "        print('Indexing')\n",
    "    index = NNDescent(x)\n",
    "    neighbors = np.empty((num_pts, k), dtype=np.int32)\n",
    "    p_ij = np.empty((num_pts, k))\n",
    "    for i, xi in enumerate(x):\n",
    "        if verbose:\n",
    "            print('Calculating probabilities: {cur}/{tot}'.format(\n",
    "                cur=i+1, tot=num_pts), end='\\r')\n",
    "        nn, dists = index.query([xi], k+1)\n",
    "        sigma = find_sigma(dists[0, 1:], k)\n",
    "        neighbors[i] = nn[0, 1:]\n",
    "        p_ij[i] = np.exp(- (dists[0, 1:] - dists[0, 1]) / sigma)\n",
    "    row_indices = np.repeat(np.arange(num_pts), k)\n",
    "    p = csr_matrix((p_ij.ravel(), (row_indices, neighbors.ravel())))\n",
    "    return p + p.transpose() - (p.multiply(p.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Indexing\n"
     ]
    }
   ],
   "source": [
    "p = p_ij_sym(iris.to_numpy()[:,:4], 20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = pp.row\n",
    "tail = pp.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_sample = np.asarray(500 * pp.data, np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_exp, edges_from_exp = (\n",
    "        np.repeat(head, num_per_sample),\n",
    "        np.repeat(tail, num_per_sample),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_mask = np.random.permutation(range(len(edges_to_exp)))\n",
    "edges_to_exp = edges_to_exp[shuffle_mask].astype(np.int32)\n",
    "edges_from_exp = edges_from_exp[shuffle_mask].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(edges_to_exp), torch.tensor(edges_from_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    emb_to, emb_from = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = torch.stack((tox, fromx)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_neg_to = torch.repeat_interleave(emb_to, 5)\n",
    "repeat_neg = torch.repeat_interleave(emb_from, 5)\n",
    "emb_neg_from = repeat_neg[torch.randperm(repeat_neg.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.811"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "(pp.toarray()[emb_neg_from, emb_neg_to] == 0.).sum() / len(emb_neg_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        distance_embedding = tf.concat(\r\n",
    "            [\r\n",
    "                tf.norm(embedding_to - embedding_from, axis=1),\r\n",
    "                tf.norm(embedding_neg_to - embedding_neg_from, axis=1),\r\n",
    "            ],\r\n",
    "            axis=0,\r\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76b22f2d16ad6fe83001a338aacb6eece0f02ecda19b2433097d5d6b62848fa1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ml': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}